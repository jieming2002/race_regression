{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking 集成算法\n",
    "基础学习器抽取特征，次级学习器融合。5折。\n",
    "- 8 神经网络回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的工具包\n",
    "import numpy as np #用于数值计算\n",
    "import pandas as pd #用于数据表处理，数据文件读写\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt #用于绘图：分析结果的可视化。\n",
    "#应该是设置浮点数的形式格式，小数点后三位\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "#这一行是干嘛的？ 设置 matplotlib 让绘制的图形出现在 Notebook 里而不是新窗口\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_val(val_id):\n",
    "    '''获取训练集和校验集 \n",
    "    val_id = 0,1,2 #当前校验集编号 '''\n",
    "    print('val_id=%s'% (val_id))\n",
    "    df_val = train_list[val_id]\n",
    "    train_tmp = []\n",
    "\n",
    "    for i in range(1, train_part_num):\n",
    "        cur_id = (val_id + i) % 5\n",
    "        print('cur_id=%s'% (cur_id))\n",
    "        train_tmp.append(train_list[cur_id])\n",
    "    \n",
    "#     只生成一次，节省内存 \n",
    "    df_train = pd.concat(train_tmp)\n",
    "    print('df_train.shape=%s  df_val.shape=%s'% (df_train.shape, df_val.shape))\n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_Standard = True\n",
    "path_train = '../data/new/train=all/'\n",
    "path_test = '../data/new/test/'\n",
    "\n",
    "val_path = '../data/val/' #保存校验集测试结果\n",
    "val_name = '%sval=stacking-%s-%s.csv'\n",
    "summit_path = '../data/summit/' #保存提交文件，测试集测试结果 \n",
    "out_name = '%ssummit=stacking-%s-%s.csv' # 生成的结果文件名称\n",
    "\n",
    "train_part_num = 5 #训练集拆分个数\n",
    "target = 'prediction_pay_price'\n",
    "user_id = 'user_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定读取数据类型，节省内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_int32 = ['user_id', 'register_time', 'wood_add_value', 'wood_reduce_value',\n",
    "       'stone_add_value', 'stone_reduce_value', 'ivory_add_value',\n",
    "       'ivory_reduce_value', 'meat_add_value', 'meat_reduce_value',\n",
    "       'magic_add_value', 'magic_reduce_value', 'infantry_add_value',\n",
    "       'infantry_reduce_value', 'cavalry_add_value', 'cavalry_reduce_value',\n",
    "       'shaman_add_value', 'shaman_reduce_value', 'wound_infantry_add_value',\n",
    "       'wound_infantry_reduce_value', 'wound_cavalry_add_value',\n",
    "       'wound_cavalry_reduce_value', 'wound_shaman_add_value',\n",
    "       'wound_shaman_reduce_value', 'general_acceleration_add_value',\n",
    "       'general_acceleration_reduce_value', 'building_acceleration_add_value',\n",
    "       'building_acceleration_reduce_value', 'reaserch_acceleration_add_value',\n",
    "       'reaserch_acceleration_reduce_value', 'training_acceleration_add_value',\n",
    "       'training_acceleration_reduce_value', 'treatment_acceleraion_add_value',\n",
    "       'treatment_acceleration_reduce_value', 'bd_training_hut_level',\n",
    "       'bd_healing_lodge_level', 'bd_stronghold_level',\n",
    "       'bd_outpost_portal_level', 'bd_barrack_level',\n",
    "       'bd_healing_spring_level', 'bd_dolmen_level', 'bd_guest_cavern_level',\n",
    "       'bd_warehouse_level', 'bd_watchtower_level', 'bd_magic_coin_tree_level',\n",
    "       'bd_hall_of_war_level', 'bd_market_level', 'bd_hero_gacha_level',\n",
    "       'bd_hero_strengthen_level', 'bd_hero_pve_level', 'sr_scout_level', \n",
    "       'sr_training_speed_level', 'sr_infantry_tier_2_level',\n",
    "       'sr_cavalry_tier_2_level', 'sr_shaman_tier_2_level',\n",
    "       'sr_infantry_atk_level', 'sr_cavalry_atk_level', 'sr_shaman_atk_level',\n",
    "       'sr_infantry_tier_3_level', 'sr_cavalry_tier_3_level',\n",
    "       'sr_shaman_tier_3_level', 'sr_troop_defense_level',\n",
    "       'sr_infantry_def_level', 'sr_cavalry_def_level', 'sr_shaman_def_level',\n",
    "       'sr_infantry_hp_level', 'sr_cavalry_hp_level', 'sr_shaman_hp_level',\n",
    "       'sr_infantry_tier_4_level', 'sr_cavalry_tier_4_level',\n",
    "       'sr_shaman_tier_4_level', 'sr_troop_attack_level',\n",
    "       'sr_construction_speed_level', 'sr_hide_storage_level',\n",
    "       'sr_troop_consumption_level', 'sr_rss_a_prod_levell',\n",
    "       'sr_rss_b_prod_level', 'sr_rss_c_prod_level', 'sr_rss_d_prod_level',\n",
    "       'sr_rss_a_gather_level', 'sr_rss_b_gather_level',\n",
    "       'sr_rss_c_gather_level', 'sr_rss_d_gather_level', 'sr_troop_load_level',\n",
    "       'sr_rss_e_gather_level', 'sr_rss_e_prod_level',\n",
    "       'sr_outpost_durability_level', 'sr_outpost_tier_2_level',\n",
    "       'sr_healing_space_level', 'sr_gathering_hunter_buff_level',\n",
    "       'sr_healing_speed_level', 'sr_outpost_tier_3_level',\n",
    "       'sr_alliance_march_speed_level', 'sr_pvp_march_speed_level',\n",
    "       'sr_gathering_march_speed_level', 'sr_outpost_tier_4_level',\n",
    "       'sr_guest_troop_capacity_level', 'sr_march_size_level',\n",
    "       'sr_rss_help_bonus_level', 'pvp_battle_count', 'pvp_lanch_count',\n",
    "       'pvp_win_count', 'pve_battle_count', 'pve_lanch_count', 'pve_win_count',\n",
    "       'pay_count']\n",
    "col_float32 = ['avg_online_minutes', 'pay_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 指定读取数据类型，节省内存\n",
    "dtype_test = {}\n",
    "for col in col_int32:\n",
    "    dtype_test[col] = np.int32\n",
    "for col in col_float32:\n",
    "    dtype_test[col] = np.float32\n",
    "# dtype_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_train = dtype_test.copy()\n",
    "dtype_train[target] = np.float32\n",
    "# dtype_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据，一次读取多次使用，不同组合 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>register_time</th>\n",
       "      <th>wood_add_value</th>\n",
       "      <th>wood_reduce_value</th>\n",
       "      <th>stone_add_value</th>\n",
       "      <th>stone_reduce_value</th>\n",
       "      <th>ivory_add_value</th>\n",
       "      <th>ivory_reduce_value</th>\n",
       "      <th>meat_add_value</th>\n",
       "      <th>meat_reduce_value</th>\n",
       "      <th>...</th>\n",
       "      <th>pvp_battle_count</th>\n",
       "      <th>pvp_lanch_count</th>\n",
       "      <th>pvp_win_count</th>\n",
       "      <th>pve_battle_count</th>\n",
       "      <th>pve_lanch_count</th>\n",
       "      <th>pve_win_count</th>\n",
       "      <th>avg_online_minutes</th>\n",
       "      <th>pay_price</th>\n",
       "      <th>pay_count</th>\n",
       "      <th>prediction_pay_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332994</td>\n",
       "      <td>112</td>\n",
       "      <td>43413</td>\n",
       "      <td>18424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62775</td>\n",
       "      <td>9444</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2186887</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>383991</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102315</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225310</td>\n",
       "      <td>106</td>\n",
       "      <td>28975</td>\n",
       "      <td>5780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33525</td>\n",
       "      <td>3220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  register_time  wood_add_value  wood_reduce_value  stone_add_value  \\\n",
       "0   332994            112           43413              18424                0   \n",
       "1  2186887            136               0                  0                0   \n",
       "2   383991            134               0                  0                0   \n",
       "3   102315            134               0                  0                0   \n",
       "4   225310            106           28975               5780                0   \n",
       "\n",
       "   stone_reduce_value  ivory_add_value  ivory_reduce_value  meat_add_value  \\\n",
       "0                   0                0                   0           62775   \n",
       "1                   0                0                   0               0   \n",
       "2                   0                0                   0               0   \n",
       "3                   0                0                   0               0   \n",
       "4                   0                0                   0           33525   \n",
       "\n",
       "   meat_reduce_value          ...           pvp_battle_count  pvp_lanch_count  \\\n",
       "0               9444          ...                          0                0   \n",
       "1                  0          ...                          0                0   \n",
       "2                  0          ...                          0                0   \n",
       "3                  0          ...                          0                0   \n",
       "4               3220          ...                          0                0   \n",
       "\n",
       "   pvp_win_count  pve_battle_count  pve_lanch_count  pve_win_count  \\\n",
       "0              0                 0                0              0   \n",
       "1              0                 0                0              0   \n",
       "2              0                 0                0              0   \n",
       "3              0                 0                0              0   \n",
       "4              0                 0                0              0   \n",
       "\n",
       "   avg_online_minutes  pay_price  pay_count  prediction_pay_price  \n",
       "0              0.5000     0.0000          0                0.0000  \n",
       "1              0.3333     0.0000          0                0.0000  \n",
       "2              0.6667     0.0000          0                0.0000  \n",
       "3              0.5000     0.0000          0                0.0000  \n",
       "4              0.6667     0.0000          0                0.0000  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = []\n",
    "for i in range(train_part_num):\n",
    "    cur_id = i + 1\n",
    "    train_list.append(pd.read_csv('%strain=fe-%s.csv' % (path_train, cur_id), dtype=dtype_train))\n",
    "train_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_id=0\n",
      "cur_id=1\n",
      "cur_id=2\n",
      "cur_id=3\n",
      "cur_id=4\n",
      "df_train.shape=(1830404, 109)  df_val.shape=(457602, 109)\n"
     ]
    }
   ],
   "source": [
    "# 根据校验集编号 0，1,2,3,4 ，获取训练集和校验集\n",
    "df_train, df_val = get_train_val(0)\n",
    "\n",
    "# 从原始数据中分离输入特征x和输出y\n",
    "train_y = df_train[target].values\n",
    "train_X = df_train.drop([target, user_id], axis = 1)\n",
    "val_y = df_val[target].values\n",
    "val_X = df_val.drop([target, user_id], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据标准化：分别初始化对特征和目标值的标准化器 \n",
    "ss_X = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征以及目标值进行标准化处理\n",
    "train_X_ss = ss_X.fit_transform(train_X)\n",
    "val_X_ss = ss_X.transform(val_X)\n",
    "\n",
    "if Y_Standard:\n",
    "    train_y_ss = ss_y.fit_transform(train_y.reshape(-1, 1))\n",
    "    val_y_ss = ss_y.transform(val_y.reshape(-1, 1))\n",
    "\n",
    "# 需要转换为一维数组 \n",
    "train_y_ss_1d = train_y_ss.reshape(train_y_ss.shape[0])\n",
    "val_y_ss_1d = val_y_ss.reshape(val_y_ss.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457602, 107)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_StandardScaler(predict):\n",
    "    ''' 标准化数据还原  '''    \n",
    "    if Y_Standard:\n",
    "        predict = ss_y.inverse_transform(predict)\n",
    "        print('predict = ', predict)\n",
    "    return predict\n",
    "\n",
    "def generate_summit(predict):\n",
    "    ''' 输出预测后的数据 '''\n",
    "    testPredict = test.copy()\n",
    "    testPredict[target] = predict\n",
    "    testPredict = testPredict[[user_id, target]]\n",
    "#     应该过滤掉负数\n",
    "    testPredict[target] = testPredict[target].apply(lambda x: x if x > 0 else 0)\n",
    "    return testPredict\n",
    "\n",
    "def generate_val_predict(predict):\n",
    "    ''' 生成校验集预测后的数据 '''\n",
    "    testPredict = df_val.copy()\n",
    "    testPredict[target] = predict\n",
    "    testPredict = testPredict[[user_id, target]]\n",
    "#     应该过滤掉负数\n",
    "    testPredict[target] = testPredict[target].apply(lambda x: x if x > 0 else 0)\n",
    "    return testPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>register_time</th>\n",
       "      <th>wood_add_value</th>\n",
       "      <th>wood_reduce_value</th>\n",
       "      <th>stone_add_value</th>\n",
       "      <th>stone_reduce_value</th>\n",
       "      <th>ivory_add_value</th>\n",
       "      <th>ivory_reduce_value</th>\n",
       "      <th>meat_add_value</th>\n",
       "      <th>meat_reduce_value</th>\n",
       "      <th>...</th>\n",
       "      <th>sr_rss_help_bonus_level</th>\n",
       "      <th>pvp_battle_count</th>\n",
       "      <th>pvp_lanch_count</th>\n",
       "      <th>pvp_win_count</th>\n",
       "      <th>pve_battle_count</th>\n",
       "      <th>pve_lanch_count</th>\n",
       "      <th>pve_win_count</th>\n",
       "      <th>avg_online_minutes</th>\n",
       "      <th>pay_price</th>\n",
       "      <th>pay_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14933</td>\n",
       "      <td>94</td>\n",
       "      <td>166415</td>\n",
       "      <td>138362</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258522</td>\n",
       "      <td>90142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14934</td>\n",
       "      <td>94</td>\n",
       "      <td>10000</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14935</td>\n",
       "      <td>94</td>\n",
       "      <td>10000</td>\n",
       "      <td>3700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14936</td>\n",
       "      <td>94</td>\n",
       "      <td>210000</td>\n",
       "      <td>0</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>610000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14937</td>\n",
       "      <td>94</td>\n",
       "      <td>11500</td>\n",
       "      <td>3700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11000</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  register_time  wood_add_value  wood_reduce_value  stone_add_value  \\\n",
       "0    14933             94          166415             138362                0   \n",
       "1    14934             94           10000                600                0   \n",
       "2    14935             94           10000               3700                0   \n",
       "3    14936             94          210000                  0           200000   \n",
       "4    14937             94           11500               3700                0   \n",
       "\n",
       "   stone_reduce_value  ivory_add_value  ivory_reduce_value  meat_add_value  \\\n",
       "0                   0                0                   0          258522   \n",
       "1                   0                0                   0           10000   \n",
       "2                   0                0                   0           10000   \n",
       "3                   0           200000                   0          610000   \n",
       "4                   0                0                   0           11000   \n",
       "\n",
       "   meat_reduce_value    ...      sr_rss_help_bonus_level  pvp_battle_count  \\\n",
       "0              90142    ...                            0                 0   \n",
       "1                400    ...                            0                 0   \n",
       "2               2000    ...                            0                 0   \n",
       "3                  0    ...                            0                 0   \n",
       "4               2000    ...                            0                 0   \n",
       "\n",
       "   pvp_lanch_count  pvp_win_count  pve_battle_count  pve_lanch_count  \\\n",
       "0                0              0                 1                1   \n",
       "1                0              0                 0                0   \n",
       "2                0              0                 0                0   \n",
       "3                0              0                 0                0   \n",
       "4                0              0                 0                0   \n",
       "\n",
       "   pve_win_count  avg_online_minutes  pay_price  pay_count  \n",
       "0              1              8.0000     0.0000          0  \n",
       "1              0              0.1667     0.0000          0  \n",
       "2              0             17.0000     0.0000          0  \n",
       "3              0              1.6667     0.0000          0  \n",
       "4              0              0.3333     0.0000          0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(path_test + 'tap_fun_test-fe.csv', dtype=dtype_test)\n",
    "test_X = test.drop([user_id], axis = 1)\n",
    "test_X_ss = ss_X.transform(test_X)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "###  8 神经网络回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    '''添加层，返回本层的输出项\n",
    "    in_size 输入节点个数\n",
    "    out_size 输出节点个数\n",
    "    '''\n",
    "    #在ReLU 激活函数中推荐使用 Xavier 初始化的变种，暂且称之为 He Initialization：\n",
    "    Weights = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.5)) / np.sqrt(in_size / 2)\n",
    "    \n",
    "    #计算正则项，加入集合losses里面\n",
    "#     reg = tf.contrib.layers.l1_regularizer(0.0001)(Weights)\n",
    "    reg = tf.contrib.layers.l1_regularizer(0.01)(Weights)\n",
    "#     reg = tf.contrib.layers.l1_regularizer(0.1)(Weights)\n",
    "    tf.add_to_collection(\"losses\", reg)\n",
    "    \n",
    "    # 偏置初始化分布参数设置  \n",
    "    biases = tf.Variable(tf.constant(0.1, shape=[out_size]))\n",
    "    \n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "n_input = train_X_ss.shape[1]\n",
    "n_output = train_y_ss.shape[1]\n",
    "tf_x = tf.placeholder(tf.float32, [None,n_input])     # input x\n",
    "tf_y = tf.placeholder(tf.float32, [None,n_output])     # input y\n",
    "\n",
    "# 神经元数量=数据维度 ,添加隐层，调整神经元个数，看看效果 \n",
    "# layer_dim = [n_input, 107, n_output]\n",
    "# layer_dim = [n_input, 107, 50, n_output]\n",
    "# layer_dim = [n_input, 107, 50, 20, n_output]\n",
    "layer_dim = [n_input, 55, 27, n_output]\n",
    "n_layers = len(layer_dim) #神经网络的层数\n",
    "\n",
    "output_layer = tf_x\n",
    "in_dimension = layer_dim[0]\n",
    "for i in range (1, n_layers):\n",
    "    out_dimension = layer_dim[i]\n",
    "    if out_dimension == n_output:\n",
    "        active_fun = None \n",
    "    else: #调整激活函数\n",
    "#         active_fun = tf.nn.relu6\n",
    "        active_fun = tf.nn.relu\n",
    "    \n",
    "    # 添加层：有 out_dimension 个神经元 \n",
    "    output_layer = add_layer(output_layer, in_dimension, out_dimension, activation_function=active_fun)\n",
    "    in_dimension = layer_dim[i]\n",
    "#     cur_layer = tf.layers.batch_normalization(cur_layer) #加快收敛\n",
    "#     cur_layer = tf.layers.dropout(cur_layer, rate=0.5) #防止过拟合\n",
    "\n",
    "loss = tf.losses.mean_squared_error(tf_y, output_layer)   # compute cost 损失函数 \n",
    "tf.add_to_collection(\"losses\", loss)#把交叉熵损失，也加入到集合里\n",
    "\n",
    "# 调整优化器和学习率 \n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_validation(epoch):\n",
    "    ''' 模型校验 '''\n",
    "#     train_loss = sess.run(loss, {tf_x: X_train_part, \n",
    "#                                     tf_y: y_train_part})\n",
    "    val_loss, val_pred = sess.run([loss, output_layer], {tf_x: val_X_ss, \n",
    "                                    tf_y: val_y_ss})\n",
    "    if epoch % 1 == 0:\n",
    "        print('---------------- epoch=%s  val_loss=%s' % (epoch+1, val_loss))\n",
    "    \n",
    "    return val_loss, val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_sample=1830404 batch_size=457602 n_step=4 n_epoch=220\n"
     ]
    }
   ],
   "source": [
    "# 训练参数\n",
    "n_sample = train_X_ss.shape[0]\n",
    "# batch_size = int(n_sample / 2)\n",
    "# batch_size = 20592\n",
    "batch_size = 457602\n",
    "# batch_size = 228801\n",
    "# batch_size = 114400\n",
    "n_step = int(np.ceil(n_sample / batch_size))\n",
    "n_epoch = 220\n",
    "early_stopping_max = 10\n",
    "early_stopping_threshold = 0.3\n",
    "print('n_sample=%s batch_size=%s n_step=%s n_epoch=%s' % (n_sample, batch_size, n_step, n_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- epoch=1  val_loss=1.3358054\n",
      "14.86s/epoch  loss=0.9393394\n",
      "---------------- epoch=2  val_loss=1.3073058\n",
      "14.94s/epoch  loss=0.9004526\n",
      "---------------- epoch=3  val_loss=1.2825257\n",
      "14.97s/epoch  loss=0.86473143\n",
      "---------------- epoch=4  val_loss=1.2590096\n",
      "15.12s/epoch  loss=0.83135134\n",
      "---------------- epoch=5  val_loss=1.2375165\n",
      "15.4s/epoch  loss=0.8000157\n",
      "---------------- epoch=6  val_loss=1.217648\n",
      "14.84s/epoch  loss=0.770365\n",
      "---------------- epoch=7  val_loss=1.198733\n",
      "14.73s/epoch  loss=0.7419497\n",
      "---------------- epoch=8  val_loss=1.1804674\n",
      "14.99s/epoch  loss=0.71494204\n",
      "---------------- epoch=9  val_loss=1.1626669\n",
      "14.72s/epoch  loss=0.6886131\n",
      "---------------- epoch=10  val_loss=1.1453732\n",
      "14.63s/epoch  loss=0.66283184\n",
      "---------------- epoch=11  val_loss=1.1282372\n",
      "14.74s/epoch  loss=0.63769853\n",
      "---------------- epoch=12  val_loss=1.111315\n",
      "14.92s/epoch  loss=0.6132628\n",
      "---------------- epoch=13  val_loss=1.0945717\n",
      "14.67s/epoch  loss=0.5893225\n",
      "---------------- epoch=14  val_loss=1.0777297\n",
      "14.63s/epoch  loss=0.56594723\n",
      "---------------- epoch=15  val_loss=1.0613208\n",
      "15.83s/epoch  loss=0.5433976\n",
      "---------------- epoch=16  val_loss=1.0455147\n",
      "15.29s/epoch  loss=0.52211934\n",
      "---------------- epoch=17  val_loss=1.0304859\n",
      "15.65s/epoch  loss=0.50218886\n",
      "---------------- epoch=18  val_loss=1.0161521\n",
      "15.48s/epoch  loss=0.48324648\n",
      "---------------- epoch=19  val_loss=1.0028808\n",
      "15.43s/epoch  loss=0.4662582\n",
      "---------------- epoch=20  val_loss=0.9911349\n",
      "15.64s/epoch  loss=0.45178264\n"
     ]
    }
   ],
   "source": [
    "# 进行训练\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "loss_train_arr = []\n",
    "loss_val_arr = []\n",
    "time_count = []\n",
    "# losses = []\n",
    "early_stopping_n = 0\n",
    "random_train = True #是否随机 batch \n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    ticks = time.time()\n",
    "#     print('=============== epoch=%s' % (epoch+1))\n",
    "    for step in range(n_step):\n",
    "        # train and net output\n",
    "        if random_train:# 随机取训练集\n",
    "            _, batch_X, _, batch_y = train_test_split(train_X_ss, train_y_ss, random_state=33, test_size=batch_size)\n",
    "        else:# 固定截取一段训练集\n",
    "            i_from = step * batch_size\n",
    "            i_to = (step+1) * batch_size\n",
    "            if i_to > (n_sample - 1): #索引越界处理 \n",
    "                i_to = (n_sample - 1)\n",
    "            batch_X, batch_y = train_X_ss[i_from:i_to], train_y_ss[i_from:i_to]\n",
    "#         print('batch_X.shape=%s  batch_y.shape=%s' % (batch_X.shape, batch_y.shape))\n",
    "        _, loss_v, pred = sess.run([train_op, loss, output_layer], {tf_x: batch_X, \n",
    "                                                         tf_y: batch_y})\n",
    "        \n",
    "#         losses.append(loss_v)\n",
    "#         if step % 5 == 0:\n",
    "#             print('step=%s loss=%s' % (step+1, loss_v))\n",
    "    mean_loss = loss_v # np.mean(losses)\n",
    "    loss_train_arr.append(mean_loss)\n",
    "    val_loss, val_pred = model_validation(epoch)\n",
    "    loss_val_arr.append(val_loss)\n",
    "    ticks = np.round((time.time() - ticks) * 100) / 100\n",
    "    time_count.append(ticks)\n",
    "    if epoch % 1 == 0:\n",
    "        print('%ss/epoch  loss=%s' % (ticks, mean_loss))\n",
    "    if val_loss < early_stopping_threshold:\n",
    "        early_stopping_n += 1\n",
    "    if early_stopping_n > 10:\n",
    "        break\n",
    "\n",
    "time_total = np.sum(time_count)\n",
    "print('time_total=%ss time_epoch=%s'%(time_total, time_count[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练次数，x 轴\n",
    "# x = np.arange(0, n_epoch, 1)\n",
    "x = np.arange(0, len(loss_val_arr), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "# plt.plot(x, loss_train_arr, '-o', label='loss_train')\n",
    "plt.plot(x, loss_train_arr, '-', label='loss_train')\n",
    "plt.plot(x, loss_val_arr, '-', label='loss_val')\n",
    "\n",
    "plt.xlabel('n_epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('val_pred= ', val_pred)\n",
    "# 标准化数据还原 \n",
    "predict_val = inverse_StandardScaler(val_pred)\n",
    "valPredict = generate_val_predict(predict_val)\n",
    "#输出预测后的数据\n",
    "valPredict.to_csv(val_name %(val_path, 'base', 'DNN_V2'), index=False)\n",
    "valPredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对测试数据进行预测\n",
    "test_pred = sess.run(output_layer, {tf_x:test_X_ss})\n",
    "print('test_pred = ', test_pred)\n",
    "\n",
    "# 标准化数据还原 \n",
    "test_pred = inverse_StandardScaler(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出预测后的数据\n",
    "testPredict = generate_summit(test_pred)\n",
    "testPredict.to_csv(out_name %(summit_path, 'base', 'DNN_V2'), index=False)\n",
    "testPredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 最后要关闭 \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
