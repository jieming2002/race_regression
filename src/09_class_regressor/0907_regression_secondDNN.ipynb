{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking 集成算法-只有付费记录：次级学习器融合-深度神经网络\n",
    "- 8 神经网络回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的工具包\n",
    "import numpy as np #用于数值计算\n",
    "import pandas as pd #用于数据表处理，数据文件读写\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt #用于绘图：分析结果的可视化。\n",
    "#应该是设置浮点数的形式格式，小数点后三位\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "#这一行是干嘛的？ 设置 matplotlib 让绘制的图形出现在 Notebook 里而不是新窗口\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_val(val_id):\n",
    "    '''获取训练集和校验集 \n",
    "    val_id = 0,1,2 #当前校验集编号 '''\n",
    "    print('val_id=%s'% (val_id))\n",
    "    df_val = train_list[val_id]\n",
    "    train_tmp = []\n",
    "\n",
    "    for i in range(1, train_part_num):\n",
    "        cur_id = (val_id + i) % 5\n",
    "        print('cur_id=%s'% (cur_id))\n",
    "        train_tmp.append(train_list[cur_id])\n",
    "    \n",
    "#     只生成一次，节省内存 \n",
    "    df_train = pd.concat(train_tmp)\n",
    "    print('df_train.shape=%s  df_val.shape=%s'% (df_train.shape, df_val.shape))\n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_Standard = True\n",
    "path_train = '../data/new/train=predict/'\n",
    "path_test = '../data/new/test=predict/'\n",
    "\n",
    "val_path = '../data/val/second/' #保存校验集测试结果\n",
    "val_name = '%sval=stacking-%s-%s.csv'\n",
    "summit_path = '../data/summit/stacking-second/' #保存提交文件，测试集测试结果 \n",
    "out_name = '%ssummit=stacking-%s-%s.csv' # 生成的结果文件名称\n",
    "base = 'second' #学习器级别 \n",
    "\n",
    "train_part_num = 5 #训练集拆分个数\n",
    "target = 'prediction_pay_price'\n",
    "user_id = 'user_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定读取数据类型，节省内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_int32 = ['user_id']\n",
    "col_float32 = ['pred_0', 'pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5', 'pred_6', 'pred_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 指定读取数据类型，节省内存\n",
    "dtype_test = {}\n",
    "for col in col_int32:\n",
    "    dtype_test[col] = np.int32\n",
    "for col in col_float32:\n",
    "    dtype_test[col] = np.float32\n",
    "# dtype_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_train = dtype_test.copy()\n",
    "dtype_train[target] = np.float32\n",
    "# dtype_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据，一次读取多次使用，不同组合 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>prediction_pay_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332994</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2186887</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>383991</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102315</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225310</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  pred_0  pred_1  pred_2  pred_3  pred_4  pred_5  pred_6  pred_7  \\\n",
       "0   332994  0.0000  0.0001  0.0000  0.3495  0.0001  0.0000  0.0000  0.0001   \n",
       "1  2186887  0.1648  0.0001  0.0000  0.3495  0.0046  0.0000  0.1085  0.0002   \n",
       "2   383991  0.1635  0.0001  0.0000  0.3495  0.0001  0.0000  0.0527  0.0001   \n",
       "3   102315  0.1576  0.0001  0.0000  0.3495  0.0002  0.0000  0.0576  0.0001   \n",
       "4   225310  0.0000  0.0001  0.0000  0.3495  0.0007  0.0000  0.0131  0.0001   \n",
       "\n",
       "   prediction_pay_price  \n",
       "0                0.0000  \n",
       "1                0.0000  \n",
       "2                0.0000  \n",
       "3                0.0000  \n",
       "4                0.0000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = []\n",
    "for i in range(train_part_num):\n",
    "    cur_id = i + 1\n",
    "    train_list.append(pd.read_csv('%strain=pred-1-col=9-target-%s.csv' % (path_train, cur_id), dtype=dtype_train))\n",
    "train_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_id=4\n",
      "cur_id=0\n",
      "cur_id=1\n",
      "cur_id=2\n",
      "cur_id=3\n",
      "df_train.shape=(1830405, 10)  df_val.shape=(457602, 10)\n"
     ]
    }
   ],
   "source": [
    "# 根据校验集编号 0，1,2,3,4 ，获取训练集和校验集\n",
    "df_train, df_val = get_train_val(4)\n",
    "\n",
    "# 从原始数据中分离输入特征x和输出y\n",
    "train_y = df_train[target].values\n",
    "train_X = df_train.drop([target, user_id], axis = 1)\n",
    "val_y = df_val[target].values\n",
    "val_X = df_val.drop([target, user_id], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据标准化：分别初始化对特征和目标值的标准化器 \n",
    "ss_X = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征以及目标值进行标准化处理\n",
    "train_X_ss = ss_X.fit_transform(train_X)\n",
    "val_X_ss = ss_X.transform(val_X)\n",
    "\n",
    "if Y_Standard:\n",
    "    train_y_ss = ss_y.fit_transform(train_y.reshape(-1, 1))\n",
    "    val_y_ss = ss_y.transform(val_y.reshape(-1, 1))\n",
    "\n",
    "# 需要转换为一维数组 \n",
    "train_y_ss_1d = train_y_ss.reshape(train_y_ss.shape[0])\n",
    "val_y_ss_1d = val_y_ss.reshape(val_y_ss.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457602, 8)\n",
      "(1830405, 8)\n",
      "(1830405, 1)\n"
     ]
    }
   ],
   "source": [
    "print(val_X_ss.shape)\n",
    "print(train_X_ss.shape)\n",
    "print(train_y_ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_StandardScaler(predict):\n",
    "    ''' 标准化数据还原  '''    \n",
    "    if Y_Standard:\n",
    "        predict = ss_y.inverse_transform(predict)\n",
    "        print('predict = ', predict)\n",
    "    return predict\n",
    "\n",
    "def generate_summit(predict):\n",
    "    ''' 输出预测后的数据 '''\n",
    "    testPredict = test.copy()\n",
    "    testPredict[target] = predict\n",
    "    testPredict = testPredict[[user_id, target]]\n",
    "#     应该过滤掉负数\n",
    "    testPredict[target] = testPredict[target].apply(lambda x: x if x > 0 else 0)\n",
    "    return testPredict\n",
    "\n",
    "def generate_val_predict(predict):\n",
    "    ''' 生成校验集预测后的数据 '''\n",
    "    testPredict = df_val.copy()\n",
    "    testPredict[target] = predict\n",
    "    testPredict = testPredict[[user_id, target]]\n",
    "#     应该过滤掉负数\n",
    "    testPredict[target] = testPredict[target].apply(lambda x: x if x > 0 else 0)\n",
    "    return testPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14933</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>1.6502</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14934</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14935</td>\n",
       "      <td>0.3927</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14936</td>\n",
       "      <td>1.5131</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>1.3646</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14937</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  pred_0  pred_1  pred_2  pred_3  pred_4  pred_5  pred_6  pred_7\n",
       "0    14933  0.0842  0.0002  0.0079  0.4069  0.0001  0.0102  1.6502  0.0002\n",
       "1    14934  0.0592  0.0001  0.0000  0.4069  0.0000  0.0000  0.6719  0.0001\n",
       "2    14935  0.3927  0.0001  0.0000  0.4069  0.0000  0.0000  0.9312  0.0001\n",
       "3    14936  1.5131  0.0063  0.2355  0.4069  0.0000  0.2351  1.3646  0.0001\n",
       "4    14937  0.0000  0.0001  0.0000  0.4069  0.0000  0.0000  0.5996  0.0001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(path_test + 'test=pred-1-col=9.csv', dtype=dtype_test)\n",
    "test_X = test.drop([user_id], axis = 1)\n",
    "test_X_ss = ss_X.transform(test_X)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "###  8 神经网络回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    '''添加层，返回本层的输出项\n",
    "    in_size 输入节点个数\n",
    "    out_size 输出节点个数\n",
    "    '''\n",
    "    #在ReLU 激活函数中推荐使用 Xavier 初始化的变种，暂且称之为 He Initialization：\n",
    "    Weights = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.5)) / np.sqrt(in_size / 2)\n",
    "    \n",
    "    #计算正则项，加入集合losses里面\n",
    "#     reg = tf.contrib.layers.l1_regularizer(0.001)(Weights)\n",
    "    reg = tf.contrib.layers.l1_regularizer(0.01)(Weights)\n",
    "#     reg = tf.contrib.layers.l1_regularizer(0.02)(Weights)\n",
    "#     reg = tf.contrib.layers.l1_regularizer(0.1)(Weights)\n",
    "    tf.add_to_collection(\"losses\", reg)\n",
    "    \n",
    "    # 偏置初始化分布参数设置  \n",
    "    biases = tf.Variable(tf.constant(1.0, shape=[out_size]))\n",
    "#     biases = tf.Variable(tf.constant(0.1, shape=[out_size]))\n",
    "#     biases = tf.Variable(tf.constant(0.01, shape=[out_size]))\n",
    "    \n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "n_input = train_X_ss.shape[1]\n",
    "n_output = train_y_ss.shape[1]\n",
    "tf_x = tf.placeholder(tf.float32, [None,n_input])     # input x\n",
    "tf_y = tf.placeholder(tf.float32, [None,n_output])     # input y\n",
    "\n",
    "# 神经元数量=数据维度 ,添加隐层，调整神经元个数，看看效果 \n",
    "# layer_dim = [n_input, 107, n_output]\n",
    "# layer_dim = [n_input, 107, 50, n_output]\n",
    "# layer_dim = [n_input, 107, 50, 20, n_output]\n",
    "# layer_dim = [n_input, 55, 27, n_output]\n",
    "# layer_dim = [n_input, n_input*4, n_input*2, n_output]\n",
    "layer_dim = [n_input, n_input*2, n_input*1, n_output]\n",
    "# layer_dim = [n_input, n_input*1, n_input//2, n_output]\n",
    "n_layers = len(layer_dim) #神经网络的层数\n",
    "\n",
    "output_layer = tf_x\n",
    "in_dimension = layer_dim[0]\n",
    "for i in range (1, n_layers):\n",
    "    out_dimension = layer_dim[i]\n",
    "    if out_dimension == n_output:\n",
    "        active_fun = None \n",
    "    else: #调整激活函数\n",
    "#         active_fun = tf.nn.relu6\n",
    "        active_fun = tf.nn.relu\n",
    "    # 添加层：有 out_dimension 个神经元 \n",
    "    output_layer = add_layer(output_layer, in_dimension, out_dimension, activation_function=active_fun)\n",
    "    in_dimension = layer_dim[i]\n",
    "    output_layer = tf.layers.batch_normalization(output_layer) #加快收敛\n",
    "    output_layer = tf.layers.dropout(output_layer, rate=0.1) #防止过拟合\n",
    "#     output_layer = tf.layers.dropout(output_layer, rate=0.2) #防止过拟合\n",
    "\n",
    "loss = tf.losses.mean_squared_error(tf_y, output_layer)   # compute cost 损失函数 \n",
    "tf.add_to_collection(\"losses\", loss)#把交叉熵损失，也加入到集合里\n",
    "\n",
    "# 调整优化器和学习率 \n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_validation(epoch):\n",
    "    ''' 模型校验 '''\n",
    "#     train_loss = sess.run(loss, {tf_x: X_train_part, \n",
    "#                                     tf_y: y_train_part})\n",
    "    val_loss, val_pred = sess.run([loss, output_layer], {tf_x: val_X_ss, \n",
    "                                    tf_y: val_y_ss})\n",
    "    if epoch % 1 == 0:\n",
    "        print('---------------- epoch=%s  val_loss=%s' % (epoch+1, val_loss))\n",
    "    \n",
    "    return val_loss, val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_sample=1830405 batch_size=228801 n_step=8 n_epoch=50\n"
     ]
    }
   ],
   "source": [
    "# 训练参数\n",
    "n_sample = train_X_ss.shape[0]\n",
    "# batch_size = int(n_sample / 2)\n",
    "# batch_size = 20592\n",
    "# batch_size = 457602\n",
    "batch_size = 228801\n",
    "# batch_size = 114400\n",
    "n_step = int(np.ceil(n_sample / batch_size))\n",
    "n_epoch = 50\n",
    "early_stopping_max = 10\n",
    "early_stopping_threshold = 0.2\n",
    "print('n_sample=%s batch_size=%s n_step=%s n_epoch=%s' % (n_sample, batch_size, n_step, n_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- epoch=1  val_loss=2.6771355\n",
      "3.56s/epoch  loss=2.7444985\n",
      "---------------- epoch=2  val_loss=2.2232826\n",
      "3.54s/epoch  loss=2.280939\n",
      "---------------- epoch=3  val_loss=1.8457713\n",
      "3.51s/epoch  loss=1.89478\n",
      "---------------- epoch=4  val_loss=1.5389384\n",
      "3.53s/epoch  loss=1.5796533\n",
      "---------------- epoch=5  val_loss=1.2936149\n",
      "3.53s/epoch  loss=1.3270497\n",
      "---------------- epoch=6  val_loss=1.1005458\n",
      "3.54s/epoch  loss=1.1276494\n",
      "---------------- epoch=7  val_loss=0.9503306\n",
      "3.53s/epoch  loss=0.97212297\n",
      "---------------- epoch=8  val_loss=0.8352527\n",
      "3.55s/epoch  loss=0.85251695\n",
      "---------------- epoch=9  val_loss=0.7481921\n",
      "3.52s/epoch  loss=0.7616574\n",
      "---------------- epoch=10  val_loss=0.68345666\n",
      "3.52s/epoch  loss=0.69370806\n",
      "---------------- epoch=11  val_loss=0.6358171\n",
      "3.55s/epoch  loss=0.6430857\n",
      "---------------- epoch=12  val_loss=0.6008084\n",
      "3.51s/epoch  loss=0.60531217\n",
      "---------------- epoch=13  val_loss=0.57492816\n",
      "3.52s/epoch  loss=0.5767286\n",
      "---------------- epoch=14  val_loss=0.55520654\n",
      "3.53s/epoch  loss=0.5542523\n",
      "---------------- epoch=15  val_loss=0.5394702\n",
      "3.58s/epoch  loss=0.5358554\n",
      "---------------- epoch=16  val_loss=0.5259932\n",
      "3.53s/epoch  loss=0.5198555\n",
      "---------------- epoch=17  val_loss=0.513883\n",
      "3.52s/epoch  loss=0.5052036\n",
      "---------------- epoch=18  val_loss=0.5028431\n",
      "3.53s/epoch  loss=0.49170637\n",
      "---------------- epoch=19  val_loss=0.4922712\n",
      "3.51s/epoch  loss=0.47874755\n",
      "---------------- epoch=20  val_loss=0.48235622\n",
      "3.58s/epoch  loss=0.466298\n",
      "---------------- epoch=21  val_loss=0.47311673\n",
      "3.52s/epoch  loss=0.45460108\n",
      "---------------- epoch=22  val_loss=0.4645706\n",
      "3.52s/epoch  loss=0.44368345\n",
      "---------------- epoch=23  val_loss=0.45684004\n",
      "3.53s/epoch  loss=0.43359405\n",
      "---------------- epoch=24  val_loss=0.44986516\n",
      "3.56s/epoch  loss=0.42442864\n",
      "---------------- epoch=25  val_loss=0.4438933\n",
      "3.55s/epoch  loss=0.41635177\n",
      "---------------- epoch=26  val_loss=0.43879324\n",
      "3.54s/epoch  loss=0.40938735\n",
      "---------------- epoch=27  val_loss=0.4345785\n",
      "3.53s/epoch  loss=0.40339735\n",
      "---------------- epoch=28  val_loss=0.43113717\n",
      "3.53s/epoch  loss=0.39831445\n",
      "---------------- epoch=29  val_loss=0.42847136\n",
      "3.58s/epoch  loss=0.39410058\n",
      "---------------- epoch=30  val_loss=0.4263908\n",
      "3.52s/epoch  loss=0.39067847\n",
      "---------------- epoch=31  val_loss=0.4248964\n",
      "3.53s/epoch  loss=0.38793913\n",
      "---------------- epoch=32  val_loss=0.42382163\n",
      "3.53s/epoch  loss=0.3857536\n",
      "---------------- epoch=33  val_loss=0.42310116\n",
      "3.56s/epoch  loss=0.38403022\n",
      "---------------- epoch=34  val_loss=0.42262027\n",
      "3.5s/epoch  loss=0.3826793\n",
      "---------------- epoch=35  val_loss=0.4223303\n",
      "3.51s/epoch  loss=0.38162175\n",
      "---------------- epoch=36  val_loss=0.42218265\n",
      "3.53s/epoch  loss=0.38077235\n",
      "---------------- epoch=37  val_loss=0.42213437\n",
      "3.53s/epoch  loss=0.38007763\n",
      "---------------- epoch=38  val_loss=0.42216095\n",
      "3.59s/epoch  loss=0.37950382\n",
      "---------------- epoch=39  val_loss=0.42224512\n",
      "3.53s/epoch  loss=0.37895143\n",
      "---------------- epoch=40  val_loss=0.42236096\n",
      "3.53s/epoch  loss=0.37842768\n",
      "---------------- epoch=41  val_loss=0.42245978\n",
      "3.54s/epoch  loss=0.37786296\n",
      "---------------- epoch=42  val_loss=0.42256945\n",
      "3.57s/epoch  loss=0.37728494\n",
      "---------------- epoch=43  val_loss=0.42259338\n",
      "3.53s/epoch  loss=0.37665927\n",
      "---------------- epoch=44  val_loss=0.42260706\n",
      "3.53s/epoch  loss=0.37595895\n",
      "---------------- epoch=45  val_loss=0.42277038\n",
      "3.52s/epoch  loss=0.37534577\n",
      "---------------- epoch=46  val_loss=0.4229383\n",
      "3.52s/epoch  loss=0.37466195\n",
      "---------------- epoch=47  val_loss=0.42303547\n",
      "3.56s/epoch  loss=0.3741916\n",
      "---------------- epoch=48  val_loss=0.42310882\n",
      "3.52s/epoch  loss=0.3737963\n",
      "---------------- epoch=49  val_loss=0.42322072\n",
      "3.52s/epoch  loss=0.37342194\n",
      "---------------- epoch=50  val_loss=0.42333952\n",
      "3.52s/epoch  loss=0.37300646\n",
      "time_total=176.74s time_epoch=3.56\n"
     ]
    }
   ],
   "source": [
    "# 进行训练\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "loss_train_arr = []\n",
    "loss_val_arr = []\n",
    "time_count = []\n",
    "# losses = []\n",
    "early_stopping_n = 0\n",
    "random_train = True #是否随机 batch \n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    ticks = time.time()\n",
    "#     print('=============== epoch=%s' % (epoch+1))\n",
    "    for step in range(n_step):\n",
    "        # train and net output\n",
    "        if random_train:# 随机取训练集\n",
    "            _, batch_X, _, batch_y = train_test_split(train_X_ss, train_y_ss, random_state=33, test_size=batch_size)\n",
    "        else:# 固定截取一段训练集\n",
    "            i_from = step * batch_size\n",
    "            i_to = (step+1) * batch_size\n",
    "            if i_to > (n_sample - 1): #索引越界处理 \n",
    "                i_to = (n_sample - 1)\n",
    "            batch_X, batch_y = train_X_ss[i_from:i_to], train_y_ss[i_from:i_to]\n",
    "#         print('batch_X.shape=%s  batch_y.shape=%s' % (batch_X.shape, batch_y.shape))\n",
    "        _, loss_v, pred = sess.run([train_op, loss, output_layer], {tf_x: batch_X, \n",
    "                                                         tf_y: batch_y})\n",
    "        \n",
    "#         losses.append(loss_v)\n",
    "#         if step % 5 == 0:\n",
    "#             print('step=%s loss=%s' % (step+1, loss_v))\n",
    "    mean_loss = loss_v # np.mean(losses)\n",
    "    loss_train_arr.append(mean_loss)\n",
    "    val_loss, val_pred = model_validation(epoch)\n",
    "    loss_val_arr.append(val_loss)\n",
    "    ticks = np.round((time.time() - ticks) * 100) / 100\n",
    "    time_count.append(ticks)\n",
    "    if epoch % 1 == 0:\n",
    "        print('%ss/epoch  loss=%s' % (ticks, mean_loss))\n",
    "    if val_loss < early_stopping_threshold:\n",
    "        early_stopping_n += 1\n",
    "        if early_stopping_n > early_stopping_max:\n",
    "            break\n",
    "\n",
    "time_total = np.sum(time_count)\n",
    "print('time_total=%ss time_epoch=%s'%(time_total, time_count[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练次数，x 轴\n",
    "# x = np.arange(0, n_epoch, 1)\n",
    "x = np.arange(0, len(loss_val_arr), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCMAAAHkCAYAAAAEmuVjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4SYk/0N/gQoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1547a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "# plt.plot(x, loss_train_arr, '-o', label='loss_train')\n",
    "plt.plot(x, loss_train_arr, '-', label='loss_train')\n",
    "plt.plot(x, loss_val_arr, '-', label='loss_val')\n",
    "\n",
    "plt.xlabel('n_epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_pred=  [[-0.00467398]\n",
      " [-0.02422741]\n",
      " [-0.02415662]\n",
      " ...\n",
      " [-0.02045652]\n",
      " [-0.02428448]\n",
      " [-0.02425331]]\n",
      "predict =  [[ 1.4021618 ]\n",
      " [-0.3680239 ]\n",
      " [-0.3616145 ]\n",
      " ...\n",
      " [-0.02664189]\n",
      " [-0.37319043]\n",
      " [-0.37036827]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prediction_pay_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987367</td>\n",
       "      <td>1.4022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2292622</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466954</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1008130</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9759</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  prediction_pay_price\n",
       "0  1987367                1.4022\n",
       "1  2292622                0.0000\n",
       "2   466954                0.0000\n",
       "3  1008130                0.0000\n",
       "4     9759                0.0000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('val_pred= ', val_pred)\n",
    "# 标准化数据还原 \n",
    "predict_val = inverse_StandardScaler(val_pred)\n",
    "valPredict = generate_val_predict(predict_val)\n",
    "#输出预测后的数据\n",
    "valPredict.to_csv(val_name %(val_path, base, 'DNN_V2'), index=False)\n",
    "valPredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_pred =  [[-0.02066283]\n",
      " [-0.02288207]\n",
      " [-0.02205972]\n",
      " ...\n",
      " [-0.01659217]\n",
      " [-0.02357522]\n",
      " [-0.02315721]]\n",
      "predict =  [[-0.0453196 ]\n",
      " [-0.24622945]\n",
      " [-0.17178147]\n",
      " ...\n",
      " [ 0.3232002 ]\n",
      " [-0.30898073]\n",
      " [-0.27113798]]\n"
     ]
    }
   ],
   "source": [
    "#对测试数据进行预测\n",
    "test_pred = sess.run(output_layer, {tf_x:test_X_ss})\n",
    "print('test_pred = ', test_pred)\n",
    "\n",
    "# 标准化数据还原 \n",
    "test_pred = inverse_StandardScaler(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prediction_pay_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14933</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14934</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14935</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14936</td>\n",
       "      <td>0.1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14937</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  prediction_pay_price\n",
       "0    14933                0.0000\n",
       "1    14934                0.0000\n",
       "2    14935                0.0000\n",
       "3    14936                0.1170\n",
       "4    14937                0.0000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#输出预测后的数据\n",
    "testPredict = generate_summit(test_pred)\n",
    "testPredict.to_csv(out_name %(summit_path, base, 'DNN_V2'), index=False)\n",
    "testPredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 最后要关闭 \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
