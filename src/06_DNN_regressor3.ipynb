{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络回归-deepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入必要的工具包\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_Standard = True\n",
    "# 生成的结果文件编号\n",
    "out_name = '%ssummit=0.1-fe-%s.csv'\n",
    "\n",
    "# path  = '../data/new/'\n",
    "path_train = '../data/new/train=0.1/'\n",
    "path_test = '../data/new/test/'\n",
    "summit_path = '../data/summit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(path_train + 'train=0.1-fe.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(path_test + 'tap_fun_test-fe.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从原始数据中分离输入特征x和输出y\n",
    "target = 'prediction_pay_price'\n",
    "id = 'user_id'\n",
    "train_y = train[target].values\n",
    "train_X = train.drop([target, id], axis = 1)\n",
    "\n",
    "# test_id = test[id]\n",
    "test_X = test.drop([id], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_part, X_val_part, y_train_part, y_val_part = train_test_split(train_X, train_y, random_state=33, test_size=0.1)\n",
    "print('train.shape=%s X_train_part.shape=%s X_test_part.shape=%s'\n",
    "      %(train.shape, X_train_part.shape, X_val_part.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分别初始化对特征和目标值的标准化器\n",
    "ss_X = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征以及目标值进行标准化处理\n",
    "X_train_part = ss_X.fit_transform(X_train_part)\n",
    "X_val_part = ss_X.transform(X_val_part)\n",
    "test_X = ss_X.transform(test_X)\n",
    "\n",
    "if Y_Standard:\n",
    "    y_train_part = ss_y.fit_transform(y_train_part.reshape(-1, 1))\n",
    "    y_val_part = ss_y.transform(y_val_part.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 标准化数据还原 \n",
    "def inverse_StandardScaler(predict):\n",
    "    if Y_Standard:\n",
    "        predict = ss_y.inverse_transform(predict)\n",
    "        print('predict = ', predict)\n",
    "    return predict\n",
    "\n",
    "#输出预测后的数据\n",
    "def generate_summit(predict):\n",
    "    testPredict = test.copy()\n",
    "    testPredict[target] = predict\n",
    "    testPredict = testPredict[[id,target]]\n",
    "    testPredict[target] = testPredict[target].apply(lambda x: x if x > 0 else 0)\n",
    "    return testPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "n_input = X_train_part.shape[1]\n",
    "n_output = y_train_part.shape[1]\n",
    "tf_x = tf.placeholder(tf.float32, [None,n_input])     # input x\n",
    "tf_y = tf.placeholder(tf.float32, [None,n_output])     # input y\n",
    "\n",
    "# neural network layers\n",
    "# layer_dim = [100] #神经元数量=数据维度 \n",
    "# layer_dim = [107, 10, 1] #添加隐层，调整神经元个数，看看效果 \n",
    "# layer_dim = [107, 1] \n",
    "layer_dim = [107, 50, 1] \n",
    "\n",
    "active_fun = tf.nn.relu\n",
    "# active_fun = tf.nn.relu6 #调整激活函数\n",
    "\n",
    "for i, dim in enumerate(layer_dim):\n",
    "    if i == 0: # input_layer\n",
    "        hidden_layer = tf.layers.dense(tf_x, dim, active_fun) \n",
    "    elif i == (len(layer_dim) - 1):\n",
    "        output_layer = tf.layers.dense(hidden_layer, dim) \n",
    "    else:\n",
    "        hidden_layer = tf.layers.dense(hidden_layer, dim, active_fun)\n",
    "#     hidden_layer = tf.layers.batch_normalization(hidden_layer) #加快收敛\n",
    "#     hidden_layer = tf.layers.dropout(hidden_layer, rate=0.5) #防止过拟合\n",
    "\n",
    "loss = tf.losses.mean_squared_error(tf_y, output_layer)   # compute cost 损失函数 \n",
    "# 调整优化器和学习率 \n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_validation(epoch):\n",
    "    ''' 模型校验 '''\n",
    "#     train_loss = sess.run(loss, {tf_x: X_train_part, \n",
    "#                                     tf_y: y_train_part})\n",
    "    val_loss = sess.run(loss, {tf_x: X_val_part, \n",
    "                                    tf_y: y_val_part})\n",
    "    if epoch % 10 == 0:\n",
    "        print('---------------- epoch=%s  val_loss=%s' % (epoch+1, val_loss))\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "n_sample = X_train_part.shape[0]\n",
    "# batch_size = int(n_sample / 2)\n",
    "batch_size = 41184\n",
    "n_step = int(np.ceil(n_sample / batch_size))\n",
    "n_epoch = 1000\n",
    "early_stopping_max = 10\n",
    "early_stopping_threshold = 0.35\n",
    "print('n_sample=%s batch_size=%s n_step=%s n_epoch=%s' % (n_sample, batch_size, n_step, n_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 进行训练\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "loss_train_arr = []\n",
    "loss_val_arr = []\n",
    "time_count = []\n",
    "# losses = []\n",
    "early_stopping_n = 0\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    ticks = time.time()\n",
    "#     print('=============== epoch=%s' % (epoch+1))\n",
    "    for step in range(n_step):\n",
    "        # train and net output\n",
    "        i_from = step * batch_size\n",
    "        i_to = (step+1) * batch_size\n",
    "        if i_to > (n_sample - 1): #索引越界处理 \n",
    "            i_to = (n_sample - 1)\n",
    "        _, loss_v, pred = sess.run([train_op, loss, output_layer], {tf_x: X_train_part[i_from:i_to], \n",
    "                                                         tf_y: y_train_part[i_from:i_to]})\n",
    "#         losses.append(loss_v)\n",
    "#         if step % 5 == 0:\n",
    "#             print('step=%s loss=%s' % (step+1, loss_v))\n",
    "    mean_loss = loss_v # np.mean(losses)\n",
    "    loss_train_arr.append(mean_loss)\n",
    "    val_loss = model_validation(epoch)\n",
    "    loss_val_arr.append(val_loss)\n",
    "    ticks = np.round((time.time() - ticks) * 100) / 100\n",
    "    time_count.append(ticks)\n",
    "    if epoch % 10 == 0:\n",
    "        print('%ss/epoch  loss=%s' % (ticks, mean_loss))\n",
    "    if val_loss < early_stopping_threshold:\n",
    "        early_stopping_n += 1\n",
    "    if early_stopping_n > 10:\n",
    "        break\n",
    "\n",
    "time_total = np.sum(time_count)\n",
    "print('time_total=%ss time_epoch=%s'%(time_total, time_count[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练次数，x 轴\n",
    "# x = np.arange(0, n_epoch, 1)\n",
    "x = np.arange(0, len(loss_val_arr), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "# plt.plot(x, loss_train_arr, '-o', label='loss_train')\n",
    "plt.plot(x, loss_train_arr, '-', label='loss_train')\n",
    "plt.plot(x, loss_val_arr, '-', label='loss_val')\n",
    "\n",
    "plt.xlabel('n_epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对测试数据进行预测\n",
    "test_pred = sess.run(output_layer, {tf_x:test_X})\n",
    "print('test_pred = ', test_pred)\n",
    "\n",
    "# 标准化数据还原 \n",
    "test_pred = inverse_StandardScaler(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输出预测后的数据\n",
    "testPredict = generate_summit(test_pred)\n",
    "testPredict.to_csv(out_name %(summit_path, 'DNN_V3'), index=False)\n",
    "testPredict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 最后要关闭 \n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
